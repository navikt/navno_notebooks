{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Nav.no sitemap\n",
    "\n",
    "Denne notatboken analyserer\n",
    "[nav.no/sitemap.xml](https://www.nav.no/sitemap.xml). Sitemap-en beskriver alle\n",
    "åpne sider på [Nav.no](https://www.nav.no) og når de siste er oppdatert. Denne\n",
    "informasjonen er fin å bruke når man skal laste ned innholdet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for å fjerne stier som vi ikke er interessert i å indeksere\n",
    "PATH_FILTER = (\"/nav-og-samfunn/statistikk\", \"/nav-og-samfunn/kunnskap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leser inn sitemap fra internett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "raw_sitemap = httpx.get(\"https://www.nav.no/sitemap.xml\").raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "sitemap = ET.fromstring(raw_sitemap.text)\n",
    "print(f\"Antall sider i sitemap: {len(sitemap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrerer ut sider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from yarl import URL\n",
    "\n",
    "to_index: dict[URL, datetime.datetime] = {}\n",
    "\n",
    "for site in sitemap:\n",
    "    if not any([path in site[0].text for path in PATH_FILTER]):\n",
    "        url = URL(site[0].text)\n",
    "        time = datetime.datetime.fromisoformat(site[1].text)\n",
    "        to_index[url] = time\n",
    "print(f\"Antall sider etter filtrering: {len(to_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sjekk om siden er tilgjengelig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "could_not_reach: list[URL] = []\n",
    "reachable: list[URL] = []\n",
    "\n",
    "with httpx.Client() as client:\n",
    "    for site in track(to_index, description=\"Prøver å nå stier\"):\n",
    "        try:\n",
    "            resp = client.get(str(site), follow_redirects=True).raise_for_status()\n",
    "            reachable.append(URL(str(resp.url)))\n",
    "        except httpx.HTTPStatusError:\n",
    "            could_not_reach.append(site)\n",
    "\n",
    "print(f\"Antall sider som ikke kunne nåes: {len(could_not_reach)}\")\n",
    "print(f\"Antall sider som vi klarte å nå: {len(reachable)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definere datastruktur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, HttpUrl\n",
    "\n",
    "\n",
    "class SiteToIndex(BaseModel):\n",
    "    \"\"\"Representasjon av en nettside vi skal indeksere.\"\"\"\n",
    "\n",
    "    url: HttpUrl\n",
    "    \"\"\"URL til siden\"\"\"\n",
    "    json_url: HttpUrl\n",
    "    \"\"\"URL til JSON objektet vi kan hente strukturert data\"\"\"\n",
    "    last_modified: datetime.datetime | None\n",
    "    \"\"\"Når ble siden sist oppdatert\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hent ut JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "index: list[SiteToIndex] = []\n",
    "\n",
    "with httpx.Client() as client:\n",
    "    for site in track(reachable, description=\"Aksesserer JSON\"):\n",
    "        resp = client.get(\n",
    "            f\"https://www.nav.no/_next/data/latest/{site.path}.json\"\n",
    "        ).raise_for_status()\n",
    "        try:\n",
    "            last_modified = resp.json()[\"pageProps\"][\"content\"].get(\"modifiedTime\")\n",
    "            index.append(\n",
    "                SiteToIndex(\n",
    "                    url=str(site),\n",
    "                    json_url=str(resp.request.url),\n",
    "                    last_modified=last_modified,\n",
    "                )\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f\"Fant ikke 'pageProps.content' for {site}\")\n",
    "\n",
    "print(f\"Hentet JSON for {len(index)} sider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skriv til lokal JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "if local_file := Prompt.ask(\"Filnavn å skrive til (tom avbryter skriving)\"):\n",
    "    if not local_file.endswith(\".json\"):\n",
    "        local_file += \".json\"\n",
    "    with open(local_file, mode=\"w\") as fil:\n",
    "        json.dump([site.model_dump(mode=\"json\") for site in index], fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
